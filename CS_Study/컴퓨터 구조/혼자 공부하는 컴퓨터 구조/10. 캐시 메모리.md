# 캐시 메모리

- CPU 연산속도는 CPU가 메모리에 접근하는 시간에 비해 압도적으로 빠름
- 결국 CPU 연산속도가 아무리 빨라도 메모리 접근시간이 느리면 소용없음
- 이를 극복하기 위해 **캐시 메모리** 등장
- **메모리 계층 구조**를 알아야 캐시메모리를 이해 할수 있음

## 메모리 계층 구조(memory hierarchy)

- 빠르고 용량이 큰 저장 장치는 양립이 힘들다
  - CPU와 가까우면 빠르고, 멀면 느림
  - 속도가 빠른 저장 장치는 용량이 작고, 비싸다
- 컴퓨터는 그래서 다양한 저장 장치를 모두 사용
- 순서
  - 레지스터
  - 캐시 메모리
    - L1
    - L2
    - L3
  - 메인 메모리
  - 보조 기억장치
- 아래로 갈수록 CPU와 멀고, 용량이 작고, 속도가 빠르다. 가격이 싸다

## 캐시 메모리(cache memory)

- CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM기반의 저장 장치
- 메모리까지 데이터를 접근하는 속도를 극복하기 위해 등장
- 컴퓨터 내부의 여러개의 캐시 메모리가 존재
  - L1(level 1) 캐시 : 코어와 가장 가까움, 보통 코어 내부
  - L2(level 2) 캐시 : 그 다음으로 가까움, 보통 코어 내부
  - L3(level 3) 캐시 : 일반적으로 L3부터는 코어 외부에 있음
- 용량: L1 < L2 < L3
- 속도: L1 > L2 > L3
- 가격: L1 > L2 > L3
- CPU는 데이터를 먼저 L1캐시 확인후 없으면 L2, 없으면 L3순으로 검색
- 멀티 코어 프로세서는 보통 코어마다 L1,L2 캐시를 가지고 L3는 공유한다
- 코어와 제일 가까운 L1캐시를 조금이라도 더 빠르게 만들기 위해 L1 캐시를 분리하는 분리형 캐시(split cache)도 있다.
  - 명령어만 저장하는 L1l 캐시
  - 데이터만을 저장하는 L1D캐시

## 캐시히트 & 캐시 미스

- 캐시는 모든 내용을 저장할수 없다, 일부 복사해서 저장해야 할 데이터를 선택해야한다
- CPU가 사용할 법한 대상을 예측해서 저장, 예측한 데이터를 실제로 맞춰 활용되면 **캐시 히트**(cache hit)라고 한다
- 반대로 예측해 저장했지만, 틀려 직접 가져와야 하는 경우를 **캐시 미스**(cache miss)라고 함
- 캐시 적중률(cache hit ratio) = 캐시히트/ 캐시히트+ 캐시미스
- 캐시 적중률이 높을수록 성능이 좋다. 현대 컴퓨터의 적중률은 약 85~95% 이상

## 참조 지역성 원리

- 캐시 메모리는 **참조 지역성의 원리**(locality of reference, principle of locality)에 따라 가져올 데이터를 결정 및 예측

1. CPU는 최근에 접근했던 메모리에 다시 접근하는 경향이 있다 (**시간 지역성**, temporal locality)

   - 프로그래밍에서 변수 값을 저장하고 나면, 언제든 다시 변수에 접근해 저장한 값을 사용한다
   - 즉 변수에 저장된 값은 한번만 쓰지 않고, 프로그램이 실행하는 동안 여러번 사용되는 경향이 있다

2. CPU는 접근한 메모리근처를 접근하려는 경향이 있다( **공간 지역성**, spatial locality)

   - 보통 프로그램은 연관있는 데이터끼리 모여서 저장됨
   - 한번 특정 데이터를 사용했다면, 그 주변에 있는 데이터도 사용할 확률이 높다
